\chapter{Locomotion Controller Transfer from the Virtual To the Real World}
\section{Motivation}
Robotics and character animation share a common goal, to design locomotion controllers, the algorithmic ``brain'' that allow animated characters and robots to move naturally, robustly and efficiently in a complex dynamic environment. Despite this commonality, there is a gap between the state-of-the-art of these two fields. While in character animation, we have demonstrated that it is possible to control a full humanoid character to perform challenging locomotion tasks in a physically simulated environment, we have not yet seen any robots that have comparable capabilities. For example, controlling human walking is considered as a solved problem in character animation, but it is still an open research in robotics. In addition, we have demonstrated in the previous Chapters that with the powerful computational tools, controller can be optimized autonomously in a virtual environment. However, in robotics, designing controllers is still a challenging, trial-and-error process that is limited only to highly-specialized engineers. Can we extend the computational tools developed for character animations to robotics to close the gap between these two fields?

One major challenge to directly applying the methods we have developed to control robots is the Reality Gap: Controllers that work effectively for a virtual character in the simulation may perform poorly on a robot in the real environment. The most important factors that lead to the Reality Gap include hardware limitation, unmodelled dynamics, inaccurate physical properties, noise and latency. For example, the torque limits of the servos on the robot are seldom considered in animation applications. We also do not model the dynamics of the servos. Even though we often can acquire the physical properties, such as mass, center of mass and inertia, of a robot from its CAD files, they are usually inaccurate given the manufacturing error, assembly error and the cables that are not considered in CAD files. Furthermore, the noise in the environment and the latency in hardware communication also contribute to the Reality Gap.

To cross the Reality Gap and to design robotic controllers autonomously, we develop a system with three components, physical simulation, controller optimization and simulation calibration. We first build a physical simulation of articulated rigid bodies to model the dynamics of the robot and its environment. Different from the simulators used in animation, we incorporate the torque limits, servo dynamics, noise and latency measured from the robot experiments into our simulator. We then optimize a controller for a specific locomotion task in the physical simulation. However, if we apply this optimal controller directly to the robot, it will fail the task in the real world due to the Reality Gap. To solve this problem, we collect the real performance data, and use it to calibrate our physical simulator. We optimize a set of simulation parameters, including the mass, inertia, center of mass and actuator gains of the robot, to minimize the discrepancy between the simulation results and the collected real data. Through calibration, the simulator can capture the real world dynamics more faithfully. This calibrated simulator is used again in controller optimization to improve the quality of the controller. Depending on the task, it could take several iterations of simulation calibration and controller optimization to transfer the controller to the real robot. 

We evaluate our system in three locomotion tasks, rising from a leaning, sitting, or kneeling position to an erect stance. These motions are widely used in our daily life. Although most of us can perform them with ease, it is a big challenge for some elderly persons and patients with hamspring injuries. We choose to study these motions and synthesize them on robots due to these important health-care applications. One simple solution to achieve these tasks is to use static balance. The robot increases the area of the contact polygon by establishing more contact points, and then rises its body slowly while maintaining the COM within the contact polygon. We choose not to use this strategy because in real life, we human can perform these motions in a more agile fashion, and we hope that our controller can enable robots to demonstrate comparable agility. For this reason, our controllers will utilize impulsive actions and take advantage of the dynamic motion to rise. In addition, since one main contribution of our method is simulation calibration, to best test its effectiveness, we only use feedforward controllers in our evaluations. In contrast, if feedback controllers are used, the stability region of the task would be drastically increased, which makes the simulation accuracy less critical. Our results show that simulation calibration is effective. In most cases, only one iteration of calibration is needed to transfer the controller successfully to the real robot. Our system is able to design locomotion controllers autonomously, which work successfully both in the simulation and in the real world. 

\section{Overview}

\begin{figure}[!t]
  \centering
  \includegraphics[width=6in]{figures/controllerTransfer}
  \caption{Overview of our algorithm.}
  \label{fig:controllerTransferOverview}
\end{figure}

We have designed a system that can automatically design locomotion controllers for robots (Figure~\ref{fig:controllerTransferOverview}). Given the specification of the robot, including its body shape, the physical properties of each body, and the types of joints, we build a physical simulation using Dynamic Animation and Robotics Toolkit (DART) \cite{dart:2012}, an open source articulated rigid body simulator. In addition, we also take into consideration the torque limits, servo gains, noise and latency, which are not modeled in DART. The controller optimization subsystem runs thousands of simulations to search for the optimal controller to maximize the task-related fitness function. We then test this optimal controller on the robot. If the robot successfully completes the task, a working robotic controller is found and our algorithm terminates. Otherwise, we record the robot performance data and feed it into the simulation calibration subsystem. Simulation calibration runs another optimization, which searches for the optimal simulation parameters to minimize the discrepancy between the performance data from the simulation and that from the robot experiments. The loop of controller optimization and simulation calibration is performed iteratively until the controller works successfully on the real robot. In the next three sections, we will delve into the details of these main components of our system, physical simulation, controller optimization and system calibration.

\section{Physical Simulation}

\subsection{Dynamics Equations}

We model the robot as an articulated rigid body system in our simulator. We represent the states of the system $(\mathbf{x}, \dot{\mathbf{x}})$ in the generalized coordinate, where $\mathbf{x}$ include the global position $\mathbf{p}$, orientation $\mathbf{r}$ of the root link, and the joint angles $\mathbf{q}$. We solve the governing equations of motion eq.(\ref{eq:robotdynamics}) in the generalized coordinates.

\begin{equation}
\label{eq:robotdynamics}
\mathbf{M}(\mathbf{x})\mathbf{\ddot{x}}+\mathbf{C}(\mathbf{x},\mathbf{\dot{x}})=\mathbf{\tau}+\mathbf{Jf}
\end{equation}
where $\mathbf{M}(\mathbf{x})$ is the mass matrix and $\mathbf{C}(\mathbf{x},\mathbf{\dot{x}})$ is the Coriolis and Centrifugal force. $\mathbf{\tau}$ are joint torques exerted by the actuators. $\mathbf{J}$ is the Jacobian matrix and $\mathbf{f}$ is the external contact force, which is computed based on linear complementarity conditions. In our implementation, we use DART to solve eq.(\ref{eq:robotdynamics}) along with the contact forces.

\subsection{Actuator Model}

In character animations, joint torques $\tau$ are often chosen as the control signal since they can be directly integrated in eq.(\ref{eq:robotdynamics}). However, the control signal for the robot that we use in the experiments, ROBOTIS BIOLOID GP, is the desired angle $\bar{q}$ for each joint. Given difference between desired and current joint configuration ${q-\bar{q}}$, the actual servo first maps it to a corresponding power level $U$ and eventually outputs joint torque according to the internal actuator dynamics.

\begin{figure}[t]
\centering
\includegraphics[width=5in]{figures/ax18gain.eps}
\caption{The mapping between $q-\bar{q}$ and $U$ for a AX-18 motor \cite{AX18:2015}. The x-axis is $q-\bar{q}$ while the y-axis is $U$.}
\label{fig:actuatorMap}
\end{figure}

Most of the actuators on our robot are AX-18, which use the following mapping (Figure \ref{fig:actuatorMap}) between the joint angle difference $q-\bar{q}$ and the power level $U$. The inteval A and C determine the slope of the actuator response for clock-wise and counter-clock-wise motions respectively. Smaller values mean steeper response slopes, in which case the actuator follows the desired angle more closely. However, too small values can lead to overshooting problems. B and D are compliance margin. If the servo angle has only a small difference to the desired angle, specified by B and D, the servo shuts down and outputs zero torque. E, the punch, is the minimum power level before the servo shuts down. In practice, we set A and C to be the same so that the servo will behave the same no matter it rotates clock-wise or counter-clock-wise. In addition, since B, D and E are very small compared to A and C, we ignore their effects and approximate the mapping as a linear relation with slope $k_e$:
\begin{equation}
  U=k_e(q-\bar{q})
  \label{eqn:voltageErrorRelation}
\end{equation}

We adopt a model for the ideal DC motor \cite{SchwarzB:2013} to derive the relation between power level $U$ and output torque $\tau$. The assumption of using an ideal model is good since an AX-18 servo contain a high-quality DC motor. The derivation follows by considering the power balance present in the motor at a constant voltage U:
\begin{equation}
  P_{electric} = P_{mechanic} + P_{heat}
  \label{eqn:powerBalance}
\end{equation}
where $P_{electric}$ is the electrical power, $P_{mechanic}$ is the output mechanical power and $P_{heat}$ is the power dissipated as heat. From eq.(\ref{eqn:powerBalance}), we can get the following relation:
\begin{equation}
UI=\dot{q}\tau_{motor} + RI^2
\end{equation}
where $I$ is the current and $R$ is the motor winding resistance. Rearrange the above equation and plugging into the relation between $\tau$ and $I$, $\tau_{motor}=k_{\tau}I$, we arrive at the relation between $U$ and the torque generated by the motor:
\begin{equation}
  U=k_{\tau}\dot{q}+\frac{R}{k_{\tau}}\tau_{motor}
  \label{eqn:votageTorqueRelation}
\end{equation}
where $k_{\tau}$ is the torque constant, which is determined by the hardware design of the motor. The torque generated by the DC motor usually does not equal the output torque that drives the motor shaft due to the friction inside the motor. The total torque is converted into the output torque $\tau$ and the friction torque $\tau_f$.
\begin{equation}
  \tau_{motor}=\tau+\tau_f
  \label{eqn:torqueBalance}
\end{equation}
The friction torque can be further divided into viscous friction and Coulomb friction \cite{SchwarzB:2013}:
\begin{equation}
  \tau_f = -k_v\dot{q}-k_c\sgn(\dot{q})
  \label{eqn:frictionComponents}
\end{equation}
where $k_v$ and $k_c$ are friction coefficients for the viscous and Coulomb friction respectively. $\sgn(x)$ is the sign function that equals 1 if x is positive, -1 if x is negative and 0 otherwise.

Combining eq.(\ref{eqn:votageTorqueRelation}), (\ref{eqn:torqueBalance}) and (\ref{eqn:frictionComponents}), we arrive at the relation between the joint angle error $q-\bar{q}$ and the output torque $\tau$.
\begin{align}
\nonumber  \tau & = \frac{k_{\tau}k_e}{R}(q-\bar{q})+(k_v-\frac{k_{\tau}^2}{R})\dot{q}+k_c\sgn(\dot{q})\\
\nonumber & = k_p(q-\bar{q}) + k_d\dot{q} + k_c\sgn(\dot{q})\\
  \label{eqn:torqueErrorRelationSimple}
\end{align}
where $k_p=\frac{k_{\tau}k_e}{R}$ and $k_d=k_v-\frac{k_{\tau}^2}{R}$. We call these values $k_p$, $k_d$ and $k_c$ \emph{actuator gains}. Note that it is possible to compute actuator gains if the related parameters are given in the specification sheet of the motor. However, this information is not available for the motors that we use. In Chapter 6.6, we will show how to design experiments to measure these parameters. Plugging eq.(\ref{eqn:torqueErrorRelationSimple}) into (\ref{eq:robotdynamics}), and taking torque limits $[\tau_{min}, \tau_{max}]$ into consideration, we get the dynamics equation that use the reference joint motion as the control signal.
\begin{displaymath}
 \mathbf{M}(\mathbf{x})\mathbf{\ddot{x}}+\mathbf{C}(\mathbf{x},\mathbf{\dot{x}}) = \tau+\mathbf{Jf} \\
  \end{displaymath}
where 
\begin{displaymath}\tau =
  \left\{
    \begin{array}{ll}
      \tau_{min} & \text{if }\tau < \tau_{min},\\
      \tau_{max} & \text{if }\tau > \tau_{max},\\
      k_p(\mathbf{q}-\bar{\mathbf{q}}) + k_d\dot{\mathbf{q}} + k_c\sgn(\dot{\mathbf{q}}) & \text{otherwise.}\\
    \end{array}
  \right.
  \label{eqn:robotDynamicsControl}
\end{displaymath}

To guarantee the stability of the simulation, we use 1ms as the simulation time step. Many animation system use the same simulation and control frequency, which means that a control signal $\bar{\mathbf{q}}$ is updated every simulation time step. However, we find that the average latency of the whole control loop on our robot is 16ms, including the time to send actuator commands and to read sensor measurements through the serial port. To better match our simulation with the real robot situation, we choose to only update the control signal every 16 time steps.

\section{Controller Optimization}

Given the physical simulation, we can design controllers to enable the robot achieve various locomotion tasks in the simulated environment. The three tasks are rising from leaning, sitting and kneeling position to an erect stance (Figure \ref{fig:task}). For each task, the joint configuration of the initial pose and the final pose are provided by the user. The goal of the controller is to execute a sequence of control signals so that the robot can move from the initial to the final pose without losing balance. We purposefully choose to use only feedforward controllers in this work. Without feedback control, the controller transfer will not succeed even if the simulation and the real-world environment differ greatly. This can put the simulation calibration subsystem into a more thorough test. For this reason, the control signal $\bar{\mathbf{q}}(t)$ is a only function of time $t$ and does not depend on the states of the robot $\mathbf{x}$ and $\dot{\mathbf{x}}$.

\begin{figure}[!t]
  \centering
  \includegraphics[width=4in]{figures/initialFinal}
  \caption{The initial and the final joint configuration of the locomotion tasks. Top row: the initial poses of leaning, sitting and kneeling. Bottom row: the final standing pose for all three tasks.}
  \label{fig:task}
\end{figure}


We first formulate a trajectory optimization problem for each task.
\begin{align}
 \label{eqn:obj}&\max_{\bar{\mathbf{q}}(t)} E_{ctrl}(\mathbf{x}(t))\\
\nonumber  \mathrm{subject\;} &\mathrm{to} \\
\label{eqn:dyn1} & \mathbf{M}(\mathbf{x})\mathbf{\ddot{x}}+\mathbf{C}(\mathbf{x},\mathbf{\dot{x}}) =\tau + \mathbf{Jf}\\
\label{eqn:dyn2} &\tau =
  \left\{
    \begin{array}{ll}
      \tau_{min} & \text{if }\tau < \tau_{min},\\
      \tau_{max} & \text{if }\tau > \tau_{max},\\
      k_p(\mathbf{q}-\bar{\mathbf{q}}) + k_d\dot{\mathbf{q}} + k_c\sgn(\dot{\mathbf{q}}) & \text{otherwise.}\\
    \end{array}
  \right.\\
\label{eqn:boundary1}&\bar{\mathbf{x}}(0) = \mathbf{x}_0\\
\label{eqn:boundary2}&\bar{\mathbf{q}}(t) = \mathbf{q}_T, \text{if } t \geq T
\end{align}

This optimization searches for a trajectory of desired joint configuration $\bar{\mathbf{q}}(t)$ that maximize a balance related fitness function (eq.(\ref{eqn:obj})), and subject to physical constraints (eq.(\ref{eqn:dyn1}) and (\ref{eqn:dyn2})) and boundary conditions (eq.(\ref{eqn:boundary1}) and (\ref{eqn:boundary2})). $\mathbf{x}_0$ is the initial condition, and $\mathbf{q}_T$ is the final pose (Figure \ref{fig:task}), both of which are provided by the user. Note that although we can specify the global translation $\mathbf{p}_0$, rotation $\mathbf{r}_0$ and joint angles $\mathbf{q}_0$ in the initial condition, we can only specify the desired joint angles for the final state because the global translation and rotation are determined by the physical simulation.

With a reasonably chosen actuator gains, the robot can alway achieve the final pose. In this case, the criterion of success for all the tasks is whether the robot remain upright at the end of its motion. We use the following fitness function to encapsulate motions that can maintain an upright orientation.

\begin{equation}
  E_{ctrl}(\mathbf{q}(t))=\int_0^{T+1} \frac{1}{\alpha(t)+\epsilon}\mathrm{d}t
  \label{eqn:controllerObj}
\end{equation}
where $\alpha(t)$ is the angle between the up direction between in the local frame of the robot's root and in the global frame $(0,0,1)$. It measures whether the robot falls out of balance. $\epsilon$ is a small positive number to prevent the denominator being zero. We choose $\epsilon=0.1$ in all our tasks. The upper limit of the integration is $T+1$, where $T$ is the duration of the entire rising motion. The extra one second is to wait the robot to settle down. We use the time horizon $T+1$ because it is still possible that the robot can fall during the settling down phase and our fitness function needs to penalize this situation.

There are two main difficulties to solve the above optimization directly. First, the number of variables is large. Since our robot has 16 degrees of freedom and a rising motion can often take more than two seconds, the above space-time optimization problem can have more than 1000 variables. To solve the this problem, we use keyframes $\bar{\mathbf{q}}_1, \bar{\mathbf{q}}_2, ..., \bar{\mathbf{q}}_n$ to represent the trajectories of the desired poses $\bar{\mathbf{q}}(t)$. In between the keyframes, we linearly interpolated the poses from two adjacent keyframes. With this simplification, the \emph{control parameters} that we need to optimize consist a few keyframes and the time interval between two adjacent keyframes rather of a large number of poses for the entire trajectory. We further halve the search dimension by exploiting the symmetry of the motion. We find that all three tasks can be achieved with symmetric motions. Thus we constrain that the joint motions on the left bodies mirrors those of the right bodies. In addition, we hope that the controller can use agile lower-body motions to stand up instead of using the help from hands. For this reason, the freeze the joints at the shoulders and the elbows. This focus the controller to the motions of the lower body, which further reduces the size of the optimization problem.

The second difficulty is that during the motion, discrete contact events can happen frequently. They invalidate the gradient information, which imposes additional challenges for the continuous optimization algorithms. We choose to use Covariance Matrix Adaptation (CMA) \cite{Hansen:2009}, which can handle discontinous contacts, to optimize the control parameters. Starting from an initial Gaussian distribution, CMA samples this distribution for a set of control parameters, evaluates them using physical simulations, discards the inferior samples and updates the distribution according to the remaining good samples. With a number of iterations, the distribution moves and shrinks, and eventually converges to a good controller parameter that can successfully fulfill the task in the simulation.

\section{Simulation Calibration}

Although the optimal controllers $\bar{\mathbf{u}}(t)$ can work effectively in the simulation, they may fail to achieve the tasks when used on the robot due to the Reality Gap. To cross this gap, we develop a simulation calibration subsystem, whose goal is to improve the simulation accuracy, which would significantly increase the chance that the controller can be successfully transfered to the real robot. In this subsystem, we formulate an optimization (eq.~(\ref{eqn:calibration})) that searches for the \emph{simulation parameters} $\mathbf{\theta}$ so that the \emph{discrepancy} $E_{cali}$ is minimized between the simulated results and the robot performance in the real environment.

\begin{equation}
 \min_{\mathbf{\theta}} E_{cali}
\label{eqn:calibration}
\end{equation}

Many parameters $\mathbf{\theta}$ need to be set before a physical simulation starts, for example, the mass, the moment of inertia, the center of mass of each body, the coefficient of restitution, the coefficient of Coulomb friction, the gains of the actuator and many more. Changing simulation parameters can drastically alter the results of physical simulations. The accuracy of a physical simulation highly depends on the accuracy of these parameter settings. Simulation parameters are often set based on the estimation from experience, the specification of the robot, and the measurement from experiments. In our experiments, we find that many of the parameters are inaccurate. For example, the total mass of the robot is less than 1.1kg according to the CAD file while our own measurement is around 1.5kg. The height of center of mass differs more than 1cm between CAD file and our measurement. This difference in parameters could be due to the manufacturing errors and the weight of cables, glues, nuts and bolts that were used in assembling the robot. Instead of fixing the simulation parameters, we decide to adjust them during simulation calibration in order to make the simulation more accurate.

We improve the simulation accuracy by minimizing the discrepancy $E_{cali}$, which is defined as the difference between the state trajectories in simulations and those collected in real robot experiments. Recall that our entire algorithm is an iterative process. At the $n$th iteration, controller optimization outputs the optimal controller $\bar{\mathbf{u}}_n(t)$. We execute this controller on the robot for a number of times and compute the average state trajectory $\tilde{\mathbf{x}}_n(t)$ of the robot motion. We use the average of the multiple trajectories because we find that even with the same controller, we can get slightly different trajectories due to the varied initial condition, the noise from the sensor, from the actuator and from the environment. Together with the $n-1$ pairs of controllers and their associated average state trajectories from previous iterations, we can compute the discrepancy using the following expression. 

\begin{equation}
  E_{cali}=\frac{1}{n}\sum_{i=1}^{n}\int_{0}^{T+1}||\tilde{\mathbf{x}}_i(t)-\mathbf{x}_i(t)||_{\mathbf{W}}^2\mathrm{d}t
  \label{eqn:calibrationObj}
\end{equation}
where $\mathbf{x}(t)$ and $\tilde{\mathbf{x}}(t)$ are state trajectories in the simulation and in the real world respectively. $\mathbf{W}$ is a diagonal matrix, which weights the relative importance of each joint. Due to the complex interplay between the simulation results and the simulation parameters, the optimization (\ref{eqn:calibration}) is nonlinear and nonconvex.  Our numerical experiments show that the objective function has many local minima, which can impose difficulties to gradient based optimization algorithms. Similar to controller optimization, we choose to use CMA for the optimization. In this case, each CMA sample is a candidate set of simulation parameters $\mathbf{\theta}$. To evaluate each CMA sample, we set the parameters into the physical simulator, simulate the robot motion $\mathbf{x}(t)$, and then compute the objective function eq. (\ref{eqn:calibrationObj}).

In our work, we initialize the simulation parameters as follows. We set the physical properties of each body, including the mass, the moment of inertia and the COM according to the CAD files. We set the actuator gains based on the measurement from experiments. We leave all other parameters as default values in DART. Although these parameters are not accurate, they serve as a pretty good initial guess. During simulation calibration, we search the parameter space within a bounded range centered at the initial guess. In addition, we also employ two simplifications to speed up the optimization. First, we narrow down the simulation parameters to include only the actuator gains of each servo and the COM of each body. Since each task is to achieve a specific final pose while keeping balance, we believe that the actuator gains and the COM's are the two most important simulation parameters. Accurate actuator gains determines whether the robot can reach and hold the final pose, and correct COM's play an important role in balance control. This manual feature selection drastically reduce the search space of the optimization. Second, we zero out most of the diagonal entries of $\mathbf{W}$ in eq. (\ref{eqn:calibrationObj}) except for the rows corresponding to the global orientation. More specifically, we simply measure the discrepancy based solely on $\alpha$, the angle between the up direction between in the local frame of the robot's torso and in the global frame $(0,0,1)$.

\begin{equation}
  E_{cali}=\frac{1}{n}\sum_{i=1}^{n}\int_{0}^{T+1}(\tilde{\alpha}_i(t)-\alpha_i(t))^2\mathrm{d}t
  \label{eqn:calibrationObj1}
\end{equation}

The objective function eq. (\ref{eqn:calibrationObj1}) captures the most important features that characterize the success or failure of our tasks (see eq.(\ref{eqn:controllerObj})), and eliminates the potentially tedious manual tuning of the weight matrix $\mathbf{W}$.

\section{Results}
In this section we present the results of our system. Please watch the accompanying video for the controlled motions for the robot in the simulation and in the real world. Our system was implemented in C++, and we used DART with our actuator model to simulate the physics of the robot and its surrounding environments. The simulator runs in real time on a laptop with 2.6GHz CPU and 16GB of memory. In controller optimization and simulation calibration, the CMA uses 32 samples per iteration and 50 iterations. We implemented a parallel version of CMA search that can distribute the computation across all four cores on the CPU. It takes less than 15 minutes to find the optimal solution in controller optimization or simulation calibration.

To test our system on a robot, we choose a humanoid robot, BIOLOID GP, as our robotic test platform. BIOLOID GP consists of 18 degrees of freedom, powered by AX-12/AX-18 servos. The communication between our computer and the robot is through the serial port. To control the robot, a host program on the computer writes the desired pose $\bar{\mathbf{q}}$ to the serial portthat is connected to the robot. A seperate program on the robot listens to the port and sends the desired joint angle to the corresponding actuator. At the same time, the robot performance data $\tilde{\mathbf{x}}$ that will be used in simulation calibration is measured and sent back to the computer. We use onboard rotary encoders to measure joint angles and VICON motion capture system to measure the global position and orientation of the robot's torso.

\subsection{Actuator Gain Identification}
We first identify the actuator gains $k_p$, $k_d$ and $k_c$. See eq.() for the derivation of the these terms. In physical simulation, we need to set the values of the actuator gains. Unfortunately, the specification of the servos does not provide the necessary information to compute the gains. For this reason, we design a robot experiment to identify these gains. Wefirst lay the robot down and clamp it on a table except for the left foot. We then send a periodic control signal to the servo at the ankel joint (blue curve in Figure \ref{fig:actuatorId} Left). The desired joint angle stays at the maximum value for 0.67 second and changes to the minimum value for another 0.67 second and repeat. We record the trajectory of the actual joint angle through the experiment (green curve in Figure \ref{fig:actuatorId} Right). We manually segment out portions of these two curves where the desired angle $\bar{q}$ stays at the same value and where the power level is approximately linear to the error $\Delta q = \bar{q} - q$ between the desired angle and the actual angle (the union of intervals A, B, C and D in Figure \ref{fig:actuatorMap}). The black crosses ``+'' in Figure~\ref{fig:actuatorId} Right shows this error over time $\Delta q(t)$.

\begin{figure}[!t]
  \centering
  \includegraphics[width=\textwidth]{figures/actuatorId}
  \caption{Actuator Identification. Left: the time series of input desired joint angle and the measured joint angle for an AX-18 servo. Right: the time series of actual error of joint angle and the predicted error using the identified actuator gains.  }
  \label{fig:actuatorId}
\end{figure}

Given $\Delta q(t)$, we can apply regression to estimate the actuator gains. From eq. (\ref{}), we have
\begin{equation}
\ddot{\Delta q}=I^{-1}(k_p\Delta q + k_d\dot{\Delta q} + k_c\sgn{\dot{\Delta q}})
\end{equation}
where $I$ is the moment of inertia of the foot with respect to the rotating axis. The above equation is derived from the relation between angular acceleration and the torque $\tau = I\ddot{q}+\dot{I}\dot{q}$ and the fact that $\dot{I}\dot{q}=0$ because the foot is a rigid body that rotates along a fixed axis. Ideally, $\ddot{\Delta q}$ and $\dot{\Delta q}$ can be computed using finite difference. However, the measurement of $\Delta q(t)$ is too noisy and finite difference would greatly magnify the noise. To solve this problem, we first smooth $\Delta q(t)$ by performing a 4th-order polynomial regression:
\begin{equation}
  \min_{a,b,c,d,e}\int ||\Delta q(t)-(at^4+bt^3+ct^2+dt+e)||^2\mathrm{d}t
  \label{eqn:Deltaq}
\end{equation}
where $a,b,c,d,e$ are the polynomial coefficients. This regression gives us a smooth analytical expression of $\Delta q(t)$. We then compute $\ddot{\Delta q}$ and $\dot{\Delta q}$ by differentiate this polynomial analytically:
\begin{align}
\label{eqn:Deltaqdot}  \dot{\Delta q}(t)&=4at^3+3bt^2+2ct+d\\
\label{eqn:Deltaqddot}  \ddot{\Delta q}(t)&=12at^2+6bt+2c
\end{align}

Combining eq. (\ref{eqn:Deltaq}), (\ref{eqn:Deltaqdot}) and (\ref{eqn:Deltaqddot}), we can perform another regression to compute the actuator gains.
\begin{equation}
\min_{k_p, k_d, k_c}\int||\ddot{\Delta q}(t)-I^{-1}(k_p\Delta q(t) + k_d\dot{\Delta q}(t) + k_c\sgn{\dot{\Delta q}(t)})||^2\mathrm{d}t
\end{equation}

Our experiments and computation show that the actuator gains are $k_p=-9.272(N\cdot m/rad)$, $k_d=-0.3069(N\cdot m\cdot s/rad)$, and $k_c=-0.03(N\cdot m)$. To verify the correctness of the values, we plug them into the simulator and repeat the same experiment in the simulation. The red curve in Figure \ref{fig:actuatorId} Right is the error over time predicted in our simulation, which agrees well with the data that are collected from the robot experiment. After we identify the actuator gains, we test our entire system using the following three locomotion tasks.

\subsection{Rising from a Sitting Position}

\begin{figure}[!t]
  \centering
  \includegraphics[width=\textwidth]{figures/sit2Stand}
  \caption{The results of the sit-to-stand task in the simulation and on the real robot.}
  \label{fig:sit2Stand}
\end{figure}

The first task that we have tested is to rise from a sitting pose to a standing pose (Figure \ref{fig:sit2Stand}). The initial and final poses $q_0$ and $q_T$ shown in the leftmost and rightmost images in Figure \ref{fig:sit2Stand}. We parameterize the controller as three keyframes $q_0$, $q_1$ and $q_T$. In addition to $q_0$ and $q_T$ specified by the user, the controller optimization subsystem needs to search for the keyframe $q_1$, the time intervals $t_1$ and $t_2$ between three keyframes. Note that we only change the joint angles of the hips and the knees and keep all other joints motionless throughout the entire motion.

We purposefully choose the initial pose that the legs of the robot extends forward and the projection of the COM of the robot in the vertical direction falls on the seat, which is far behind the contact points of the feet. If the robot simply extends the hips and the knees to stand up, it will fall backwards. Despite this challenging setup, our system successfully finds a controller that enables the robot to stand up in the simulation. Figure \ref{fig:sit2Stand} shows that the robot first builds up a forward momentum by quickly leaning its upper body to the front. It then start to extend the hips and the knee at the right time when the COM is approaching the boundary of the contact polygon spanned by the feet. This natural sequence of motion is found automatically by the controller optimization subsystem.

When applying this controller to the real robot, we are surprised to find that it works directly, without the need of simulation calibration. The robot stands up from a chair in the same way as its simulated counterpart does in the virtual world. It shows that the Reality Gap is not always the problem. In some tasks, the stability region of a controller is so large that can make the discrepancy between the virtual and the real world less critical.

\subsection{Rising from a Leaning Position}

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.7\textwidth]{figures/lean2Stand}
  \caption{The results of the lean-to-stand task in the simulation and on the real robot.}
  \label{fig:lean2Stand}
\end{figure}

In this task, the robot need to rise from leaning on the wall (the leftmost image in Figure \ref{fig:lean2Stand}) to a standing position (the rightmost image in Figure \ref{fig:lean2Stand}). In the initial configuration, the hip joints are bent and they are straightened out in the final configuation while all other joints do not move. The initial and the final poses are the only two keyframes for this task.

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.7\textwidth]{figures/simRobotCompare}
  \caption{Comparisons of the robot's global orientation over time in the simulation (before/after calibration) and in the real environment.}
  \label{fig:simRobotCompare}
\end{figure}


The goal of controller optimization is to find an appropriate time interval between these two keyframes. If the time inteval is too long, the robot moves slowly, and cannot accumulate enough momentum to rise up. If this time inteval is too short, the robot move abruptly, which will cause the upper body to bounce off the wall too quickly and fall forward. Without simulation calibration, the optimization cannot find a working controller for this task. The robot cannot rise up when $T\leq 0.10s$ and overshoots when $T > 0.10s$. According to the objective function value, the optimal controller, which still fails the task, uses $T=0.11s$ to move from the initial to the final pose. Using this controller, the robot rises up too quickly and falls forward in the simulation. We apply this controller to the real robot. The real performance of controller differs drastically from that in the simulation. Rather than falling forward, the robot in the real world cannot rise up. The red and blue curves in Figure \ref{fig:simRobotCompare} show the discrepancy of the trajectory of robot's global orientation in the simulation and in the real world. After one iteration of simulation calibration, the discrepancy is greatly reduced (Figure \ref{fig:simRobotCompare} green curve). We optimize the controller again in the calibrated simulator. This time, the optimal controller works both in the simulated and real environment.

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.7\textwidth]{figures/fitnessLandscape}
  \caption{Comparisons of the fitness functions as more and more iterations of simulation calibration are performed.}
  \label{fig:fitnessLandscape}
\end{figure}

Our system successfully crosses the Reality Gap using only one iteration of simulation calibration. To better understand how the Reality Gap is gradually narrowed by simulation calibration over multiple iterations, we perform an additional evaluation. Figure \ref{fig:fitnessLandscape} shows the fitness function by varying the control parameter $T$ in the range of $[0, 0.11]$. The blue curve is the fitness function sampled by testing different controllers on the real robot. This serves as the ground truth. The fitness function stays at a high value when $T\in[0, 0.1]$, which means that the real robot can successfully rise if the controller uses less than 0.1s to change the pose from the initial to the final configuration. In contrast, without simulation calibration, the fitness function (lowest black curve) stays at a low value for the entire control space. In other words, no controller exists that can make the robot stand up in the simulation. The gap between the blue and the black curves is analogue to the Reality Gap. One iteration of system calibration brings the fitness function in the simulation towards the ground truth. As more iterations are performed, the fitness function in the simulation (brown and red curves) gradually approaches the ground truth, and the Reality Gap is narrowed in this process. Note that a large discrepancy still exists in the region of the parameter space where $T<0.02s$. This is probably caused by two reasons. First, torque limit is not considered in simulation calibration. In the region $T<0.02s$, the torque output of the servo is at its limit. Although we set a constant torque limit in the simulation according to the specification of the motor, it is different from the true value because the torque limit is changing with spinning speed of the motor. Second, the controllers and the data (the red circles in Figure \ref{fig:fitnessLandscape}) that we use in simulation calibration concentrate on the right half of the parameter space. This unbalanced dataset makes the calibration subsystem overfit the data. Thus it cannot generalize to a region where the data is scarce ($T<0.02$). However, this overfitting can be beneficial in many applications because the computational resource is focused at the important regions near the successful controllers.

\subsection{Rising from a Kneeling Position}

\begin{figure}[!t]
  \centering
  \includegraphics[width=\textwidth]{figures/kneel2Stand}
  \caption{The results of the kneel-to-stand task in the simulation and on the real robot.}
  \label{fig:kneel2Stand}
\end{figure}

Figure \ref{fig:kneel2Stand} shows that the robot stands up from a kneeling pose without the help of its hands. Between the user-specified initial and final poses, the controller consists of two additional keyframes. The optimization need to search for these keyframes and the time intevals between adjacent keyframes. Similar to other examples, we also freeze all the joints except for those on the lower body of the robot to reduce the search dimension. The controller optimized in the simulation demonstrates an agile getting-up motion: The robot first leans its upper-body backwards. As its COM is moving to the back, it quickly bends the hip, flexes its ankels and stands up. This entire motion resembles one of the most agile waysthat we human get up from a kneeling position without the help from our hands. Although this controller works perfectly in the simulation, the robot falls backward in the real world. After simulation calibration, the performance of this simulated robot comes closer to the real world scenario: The robot also falls backward in the simulation. Using the calibrated simulator, we optimize a new controller, with which the robot can successfully stand up from the kneeling position in the real world (Figure \ref{fig:kneel2Stand}).

\section{Discussion}

This chapter presents an end-to-end solution to automatically design robotic controllers from a locomotion task specification. This solution consists of a set of computational tools: a simulation tool that simulates the dynamics of the robot and its environment, an optimization tool that automatically searches for a controller in the virtual environment and a calibration tool that improves the simulation accuracy to ease controller transfer from the virtual to the real world. This powerful system allows us to efficiently design controllers of a humanoid robot to achieve three different tasks, rising from leaning, sitting and kneeling poses to an erect stance.

Since the main goal of this work is to demonstrate that the computational tools developed for character animations (physical simulation and controller optimization) can be applied to robotics, the biggest challenge is to cross the Reality Gap. The evaluation shows that our simulation calibration algorithm is effective to narrow this gap. In all the examples, at most one iteration of calibration is needed before we can transfer the controller to the real robot. However, we want to emphasize that goal of simulation calibration is not to find the  true simulation parameters. Instead, it finds a set of parameters that reduce the discrepancy between the simulation and the real experiment for a specific locomotion task. We observe that simulation calibration can find entirely different simulation parameters for the tasks of lean-to-stand and kneel-to-stand. In other words, the calibrated simulator is only valid for the current task and should not be used in a different task. If the tasks are the same but the initial configuations are slightly different, the result of simulation calibration can be reused. For example, in the task of lean-to-stand, with a simulator calibrated for a specific initial leaning angle, we optimize controllers for the same task but the robot needs to stand up from different initial leaning angles. Our experiments show that the result of simulation calibration can be reused if the initial leaning angle is perturbed within five degrees. 

It would be more interesting if simulation calibration can discover the truth so that the calibrated simulator can be used for different tasks. We believe that this is possible if we use multiple controllers and their related performance data for multiple different tasks as the input of simulation calibration. We leave this as one of the future work. In our examples, we have shown that adjusting the COM and actuator gains are enough, but other simulation parameters might also be important for a wider range of tasks. Including more simulation parameters and performing feature selection would be a promising direction for future work. In addition, some discrepancies between the simulation and the real world may not be explained by inaccurate simulation parameters alone. Unmodeled dynamics could also contribute to the discrepancy. How to optimize simulation parameters together with non-parametric models for unmodeled dynamics in simulation calibration is also an intereting avenue for future work.



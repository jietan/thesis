\chapter{Introduction}

Most of us human can effortlessly accomplish various locomotion tasks. We can walk, run, jump and even ride on a bicycle. In addition, Mother Nature has created an amazingly diverse set of motions in the animal kingdom. For example, birds can fly in the sky, fishes can swim in the water, geccos can crawl on a verticle surface and cats can reoriented themselves to survive a fall. Understanding and synthesizing these motions will have far-reaching impacts on a wide variety of industries, including entertainment, robotics and health care. In the entertainment industry, such as movie and games, we need to study the locomotion in nature to faithfully reproduce them on the screen, or to synthesize plausible animations for imaginary creatures. Studying  locomotion in nature can help us develop robotic controllers with extensive agility and maneuverability, such as MIT Cheetah \cite{} and Big Dog from Boston Dynamics \cite{}. These robots are expected to accomplish various missions, which are dangerous for human operators, in military, transportation, exploration and rescuing. Understanding human locomotion, can guide us build comfortable and yet powerful exoskeletons that can promote gait habilitation in children, assist paralyzed person to walk or aid normal persons to achieve superhuman ability.

Although we often take our locomotion ability for granted because we can perform them so effortlessly, it is a notoriously difficult problem because locomotion involves sophisticated neuromuscular control, sensory information processing, motion planning, coordinated muscle activation, and complicated interactions between the body and its physical environment. Despite extensive study for centuries, we have not yet fully understood the underlying physics and control mechanisms of these motions. It poses a grand challenge for scientists, engineers and artists. The focus of this thesis is to present a set of powerful computational tools that facilitate the study of the locomotion of humans and animals, for the applications in computer graphics and robotics.

\section{State of the Art}

In computer graphics, the most popular techniques to synthesize motions are key frames or motion capture. Although both methods have produced realistic character animations and special effects in movies (Toy Story \cite and Avatar \cite{}), they are not scalable and generalizable ways to synthesize motions. The key-frame method requires artistic expertise and laborious manual tuning. As a result, generating animations is a time-consuming and tedious task. For example, an 100-minute animated feature film produced by Pixar typically takes more than five years of development. On the other hand, the motion capture not only requires expensive equipment and tedious postprocessing, it is difficult to reuse the recorded data in other situations. A more principled way to synthesize motions of humans and animals is to computationally mimic the natural process that have shaped our motions. Our motions are shaped through millions of year of evolution in a world that obey physical laws. The paradigm of physically-based character animation first builds physical simulation and then optimize the motions of the character in the physically-simulated environment. Using this paradigm, many natural motions, including walking \cite{}, running \cite{}, flying \cite{} and swimming \cite{} emerge automatically from the optimization solution. In addition to these basic locomotion tasks, the research in this field has developed algorithms that allow virtual characters to recover balance from unexpected perturbations, to move in different styles, to navigate through rough terrains and to demonstrate highly skillful stunts.

Similarly, we have also seen impressive robotic systems developed in the last decade. The MIT Cheetah can run up to 20 miles per hour and jump over obstacles. Other quadrupedal robots from Boston Dynamics, Big Dog and Little Dog, can walk robustly in adversary environments, including icy or rocky terrains. The soft body robots can take advantage of their flexible bodies to navigate narrow and unstructured spaces. The humanoid robots, such as Petman and Asimo, are able demonstrate a repertoire of locomotion skills, including walking, running, dancing and climbing stairs. These amazing advance in robotics are largely attributed to the use of computational tools, including simulation, optimal control and reinforcement learning. Although these coputational tools are becoming popular and have automated some portions of the development process, the task of locomotion controller design are still limited to experts and relies on tedius manual tuning.

Despite the impressive achievements in computer graphics and robotics, the gracious, agile and diverse motions of the real creatures are far from being reproduced. Synthesizing realistic motions turns out to be a challenging problem. First of all, we are facing tremendous challenges in faithfully simulate the physical environment. For example, we have not found accurate mathematical models to describe certain physical phenomena while some dynamical systems are computationally expensive or even infeasible to simulate. More importantly, locomotion tasks often involve forceful interactions between two dynamical systems, the character itself and the surrounding environment. Since these two systems are often governed by different types of equations and simulated with different algorithms, modeling the two-way interaction between them presents a nontrivial task. An accurate and efficient physical simulator is not enough. Without proper control of muscle contactions and joint torques, a virtual character cannot move in a meaningful way to achieve an intended goal. Finding a good control mechanism poses a different set of challenges. One of the challenges is under-actuation. The movement of the center of mass (COM) can only be achieved indirectly through carefully planned interactions, such as contact, with the environment. Balance is another big challenge in locomotion. Humans and many animals are inherently unstable because their COM are above the supporting feet. The characters that we wish to control may have a large number of muscles (actuators), which need to be activated in a coordinated fashion. This results in a high dimensional nonconvex optimization problem, which can be computationally infeasible. Motion optimizing with physical constraints introduces additional difficulties. For example, the state-of-the-art contact models can invalidate the gradient, which is essential in modern optimization solvers.

Generally speaking, controlling high-dimensional dynamic systems, governed by highly nonlinear differential equations and coupled through complex mechanisms, is considered a nearly unsolvable problem. As a result, most of the prior research make simplifications on simulation models and optimization algorithms to make the computation tractable. However, many of these simplifications were made without considering the optimality of the control problems. In this thesis, we will investigate some of these simplifications and develop novel algorithms for those components that should not be simplified. 


\section{Thesis Overview}

This thesis presents a set of computational tools to study locomotion in complex physical environments. Two common algorithmic components across all the works in this thesis are physical simulation and motion optimization. In contrast to prior works that use simplified physical models, we develop new algorithms to improve and to combine the state-of-the-art simulation and optimization techniques to tackle the challenges of motion synthesis. We start with a survey of related work in the fields of computer graphics and robotics (Chapter 2). We then investigate motor control for various locomotion tasks in a hydrodynamic environment (Chapter 3), for soft body characters (Chapter 4) and with a passive mechanical device (Chapter 5). In Chapter 6, we explore the techniques to transfer the controllers developed in the simulation to robots operating in the real world. We conclude the thesis with conclusions and suggestions for future work (Chapter 7).

\subsection{Locomotion in Hydrodynamic Environment}



\begin{figure}[!h]
  \centering
    \includegraphics[width=\textwidth]{figures/teaserSwimming.eps}
  \caption{Aquatic creatures swim in a physically simulated hydrodynamic environment.}
  \label{fig:teaser1}
\end{figure}

The oceans covers over seventy percent of the area on our planet. They contain a wide variety of creatures that use swimming as their primary form of locomotion. Scientific studies show that the swimming gaits of the aquatic creatures are highly efficient compared to the man-made underwater vehicles. Studying their swimming motions could help us discover better propulsion mechanisms and design more efficient undersea vehicles to explore the largest uncharted territory on our planet. In Chapter 3, we apply numerical optimization to automatically discover the most energy efficient swimming gaits for given aquatic creatures in a physically-simulated hydrodynamic environment.

A main challenge in physical simulation is to model the complex interaction between two different types of dynamic systems, such as the two-way coupling between the fluid and a swimmer represented as an articulated rigid body system. We present an accurate physical simulator \cite{} that simultaneously solves the Navier-Stokes equations for fluids, the Lagrangian dynamics for an articulated rigid body and matches their accelerations at fluid-solid boundaries. The simulation results of swimming fish and eels show vortex trails that are in agreement with laboratory measurements.

Simulating fluid itself is hard; optimizing locomotion in a hydrodynamic environment is even more challenging. Previous methods have resorted to simplified fluid models. However, studies have shown that fish takes advantage of surrounding vortices, which are omitted in the simplified models, to provide energy boosts. Incorporating an accurate Navier-Stokes fluid model in the simulation presents new challenges in controller optimization: The optimization space is full of local minima due to the chaotic fluid behavior. Evaluating the gradient of the objective function is time-consuming. We demonstrated that sampling-based optimization algorithms, which are robust to local minima and are gradient free, are effective tools to overcome these challenges. This approach found efficient swimming motions that are comparable to those of real-world animals (Figure \ref{fig:teaser1}). 

\subsection{Locomotion for Soft Body Characters}

\begin{figure}[!h]
  \centering
    \includegraphics[width=\textwidth]{figures/teaserSoftBody.eps}
  \caption{Four alphabetic soft body characters perform different forms of locomotion.}
  \label{fig:teaser2}
\end{figure}

While most research in character animation and robotics focus on characters that are made exclusively from rigid parts, we have seen an increasingly amount of efforts in the last few years to develop soft body robots \cite{}. While these research demonstrates a huge potential of soft body robots and their broad applications, it demands a new set of computational tools to study and to synthesize motions for soft body characters.

To model soft body characters, we not only need to simulate the passive dynamics of deformation, but also the actuation of muscles. In Chapter 4, we present a new mathematical model for artificial muscles that are motivated by the muscle structures of soft body animals in nature. Similar to real muscles, these artificial ones are arranged in groups and only allowed to contract. Complex movements need to be accomplished by the coordinated contraction of multiple muscle groups. We develope a finite element method with this muscle model to simulate soft body animals.

Optimizing controllers in the presence of discontinuous contact forces is a long-standing problem. Controlling locomotion for soft body characters (Figure \ref{fig:teaser2}) exacerbates the difficulty. The deformation of the body constantly changes the contact configuration between the character and the ground. A common practice is to separate contact planning and controller optimization. We identify that this simplification eliminates effective control strategies, and this causes the soft body character to lose balance. We derive an elegant solution to this problem that combines contact planning with controller optimization. We formulate a quadratic program with complementarity conditions (QPCC) and worked out an efficient solver for QPCC derived from control problems with contacts. As a result, effective control strategies emerge automatically from the QPCC solution.

\subsection{Locomotion with Mechanical Devices}

\begin{figure}[!h]
  \centering
    \includegraphics[width=\textwidth]{figures/teaserBicycle.eps}
  \caption{A human character performs stunts on a road bike, a BMX bike and a unicycle.}
  \label{fig:teaser3}
\end{figure}

Human has invented numerous mechanical tools to ease our life. Robots in the future can work much more efficiently if they can take advantage of these existing tools. Instead of manually program the robots to master each tool, we hope that they can learn how to use them autonomously. Learning to ride a bicycle is an excellent case study. The bicycle, which has greatly boosted the efficiency of locomotion, was voted as the best invention since the 19th century. Even though the dynamics of bicycles is relatively well-understood, riding a bicycle is challenging due to the inherently unstable dynamics. Controlling balance on a bicycle involves sophisticated and robust neuromechanical control, which is vital for many locomotin tasks. In Chapter 5, we present a machine learning algorithm that allows a virtual character to learn to ride a bicycle in a physically simulated environment. 

In addition to the basic maneuvers, we hope that the character can learn more challenging but visually spectacular stunts (Figure \ref{fig:teaser3}). Performing stunts requires fast reaction, precise control and years of practice, and this challenges the best human riders. When we optimize the control policies for bicycle stunts, we find that the widely-used assumption of a predetermined controller parameterization severely limits the search space and leaves the hard work to the user to design a good parameterization. We decide that optimizing the parameterization automatically is equally important as optimizing the parameters. Our algorithm evolves both the policy parameterization and the parameters simultaneously. This significantly improves the quality of the resulting controllers. Eventually, our simulated characters learn to perform a wide variety of bicycle stunts within hours, which is even faster than the best human stunt bikers.

\subsection{Locomotion Controller Transfer from Virtual to Real World}

Above three works demonstrate that with the powerful computational tools for character animation, natural, agile and robust motions can be synthesized efficiently and autonomously. However, creating lifelike robots is still an extremely challenging, trial-and-error process that is restricted to experts. The fast evolution of 3D printing technology will soon trigger a shift in the robotics industry from mass production to personalized design and fabrication, which will result in an immediate need for a faster, cheaper and more intuitive way to design robotic controllers. The computational tools we developed can potentially automate and streamline the process if we can transfer the controllers from the virtual simulation to the real world.

Transfering controllers optimized in a simulation onto a real robot is a non-trivial task. A controller that is optimized even using a state-of-art simulation often does not work in a real environment. This is known as the \emph{Reality Gap} \cite{}. This gap is caused by various simplifications in the simulation, including inaccurate physical model, unmodeled actuator dynamics, assumptions of perfect sensing and zero latency. In Chapter 6, we investigate some of these simplifications and present a general framework of simulation calibration. Simulation calibration optimizes simulation parameters to minimize the discrepancy between the data collected from real experiments on the robot and that generated in the simulation. After calibration, the simulation becomes more faithful to the real-world dynamics. Controllers that are designed with the improved simulator can work in both the virtual and the real world. 

\section{Contributions}

The computational tools presented in this dissertation provide several contributions to the communities of character animation and robotics. These contributions are as follows.

\paragraph{A stable simulation of two-way coupling between fluids and articulated rigid bodies.} We present a novel swimming simulator that can simultaneously solve the dynamics of fluids, articulated rigid bodies and their two-way interactions. Compared to the traditional two-way coupling solver that alternates the fluid update and the the rigid body update, our method is more numerically stable. We are able to use time steps of 33ms for all our experiments without any stability problem. Using larger time steps makes our simulation orders of magnitudes faster than the alternating solver. As a result, we can discover a swimming pattern with up to days of computation while using the traditional two-way coupling technique can take weeks.

\paragraph{A finite element simulation with a muscle model for soft body animals.} Based on the muscle structure of muscular hydrostat \cite{} in real soft body animals, we develop a muscle model for the simulated characters. Combined with the finite element method for the passive deformation of the body, it provides intuitive ways to control the character in a coordinated manner. The use of this muscle model not only reduces the dimensionality of the control problem and but also results in natural-looking motions.

\paragraph{A optimizatoin solver for quadratic program with complimentarity conditions.} Controlling locomotion with contacts is a long-standing problem in continuous optimization because change of contact situation (static, sliding or breaking) can introduce discontinuities to the dynamics. A commonly-used technique is to mannualy specify the contact situation and only optimize the forces under the prescripted contact situations. However, this could eliminate effective locomotion strategies. We solve this problem by formulating a generic quadratic program with complimentarity conditions. We also develop an efficient solver for QPCC problems with contacts. This method can optimize both the contact situation and forces simultaneously. As a result, many interesting and effective locomotion strategies emerge automatically from the QPCC solution.

\paragraph{A reinforcement learning algorithm that searches both the parametrization and the parameters of a policy.} We present the first reinforcement learning algorithm which demonstrate that extremely challenging locomotion tasks, such as bicycle stunts, can be learned efficiently in simulation. Most of the stunt actions are learned within one hour, which is even faster than the best human stunt biker. These results present a new benchmark for future research in reinforcement learning. The key to such an efficient learning algorithm is an evolutionary optimization that can search for the parametrization and the parameters of a control policy simultaneously. We believe that this reinforcement learning algorithm can be generalized to master other challenging locomotion tasks.

